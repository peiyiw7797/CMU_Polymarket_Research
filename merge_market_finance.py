"""Join Polymarket price history with campaign finance timelines.

The script reads the price history output generated by
``polymarket_market_collector.py`` and combines it with analyst-supplied
finance event files (one CSV per market). When no finance events are present,
the script produces gap diagnostics so downstream users can prioritise data
collection.

Finance Event Templates
-----------------------
Finance events should be stored in ``data/finance_events/<market_id>.csv``
with the columns: ``report_date`` (ISO date), ``metric`` (e.g.,
``total_receipts``), ``value`` (numeric), ``currency`` (ISO 4217 code or
blank), ``source_name``, ``source_url``, ``notes``. The script will
automatically create empty templates for any missing files.

Outputs
-------
new_research/data/market_finance_merged.csv
new_research/data/market_finance_merged.json

These datasets provide daily market prices (Yes/No) alongside the latest
available finance disclosure snapshot and a pointer to same-day finance events.
"""

from __future__ import annotations

import json
from pathlib import Path
from typing import Dict, List

import pandas as pd


BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"
PRICE_FILE = DATA_DIR / "polymarket_price_history_top20.json"
MARKETS_FILE = DATA_DIR / "polymarket_election_markets_top20.json"
FINANCE_EVENTS_DIR = DATA_DIR / "finance_events"
OUTPUT_CSV = DATA_DIR / "market_finance_merged.csv"
OUTPUT_JSON = DATA_DIR / "market_finance_merged.json"

FINANCE_EVENT_COLUMNS = [
    "report_date",
    "metric",
    "value",
    "currency",
    "source_name",
    "source_url",
    "notes",
]


def ensure_finance_event_template(market_id: str) -> Path:
    """Create an empty finance event template if none exists."""

    FINANCE_EVENTS_DIR.mkdir(exist_ok=True)
    path = FINANCE_EVENTS_DIR / f"{market_id}.csv"
    if not path.exists():
        pd.DataFrame(columns=FINANCE_EVENT_COLUMNS).to_csv(path, index=False)
    return path


def load_markets() -> Dict[str, Dict[str, object]]:
    with MARKETS_FILE.open("r", encoding="utf-8") as handle:
        markets = json.load(handle)
    return {row["market_id"]: row for row in markets}


def load_price_history(markets: Dict[str, Dict[str, object]]) -> pd.DataFrame:
    with PRICE_FILE.open("r", encoding="utf-8") as handle:
        price_payload = json.load(handle)

    # Build mapping from token_id to outcome label.
    token_outcome_map: Dict[str, str] = {}
    for market in markets.values():
        for token_id, outcome in zip(market["clob_token_ids"], market["outcomes"]):
            token_outcome_map[token_id] = outcome

    records: List[Dict[str, object]] = []
    for market_id, entries in price_payload.items():
        for entry in entries:
            outcome = token_outcome_map.get(entry["token_id"], "Unknown")
            records.append(
                {
                    "market_id": market_id,
                    "token_id": entry["token_id"],
                    "date": pd.to_datetime(entry["date"], utc=True),
                    "price": entry["price"],
                    "outcome": outcome,
                }
            )

    price_df = pd.DataFrame(records)
    if price_df.empty:
        raise RuntimeError("Price history dataset is empty; ensure collector script was executed.")

    price_wide = (
        price_df.pivot_table(
            index=["market_id", "date"],
            columns="outcome",
            values="price",
            aggfunc="last",
        )
        .reset_index()
        .sort_values(["market_id", "date"])
    )

    # Make column names friendlier (price_Yes, price_No, etc.).
    renamed_columns = {col: f"price_{col.replace(' ', '_').lower()}" for col in price_wide.columns if col not in {"market_id", "date"}}
    price_wide = price_wide.rename(columns=renamed_columns)

    return price_wide


def load_finance_events(market_id: str) -> pd.DataFrame:
    path = ensure_finance_event_template(market_id)
    df = pd.read_csv(path)
    if df.empty:
        return df

    # Standardise column casing and parse dates.
    missing_columns = set(FINANCE_EVENT_COLUMNS) - set(df.columns.str.lower())
    if missing_columns:
        raise ValueError(f"Finance event file {path} missing columns: {missing_columns}")

    df.columns = [col.lower() for col in df.columns]
    df["report_date"] = pd.to_datetime(df["report_date"], utc=True, errors="coerce")
    df = df.dropna(subset=["report_date"])

    # Sort to prepare for asof merge.
    df = df.sort_values("report_date").reset_index(drop=True)
    return df


def summarise_finance_events(events: List[Dict[str, object]]) -> str:
    if not events:
        return ""
    parts = []
    for event in events:
        metric = event.get("metric") or "metric"
        value = event.get("value")
        currency = event.get("currency")
        formatted = f"{metric}={value}" if value is not None else metric
        if currency:
            formatted += f" {currency}"
        parts.append(formatted)
    return "; ".join(parts)


def merge_market(price_slice: pd.DataFrame, finance_df: pd.DataFrame) -> pd.DataFrame:
    price_slice = price_slice.sort_values("date").reset_index(drop=True)

    if finance_df.empty:
        price_slice["latest_finance_summary"] = pd.NA
        price_slice["latest_finance_report_date"] = pd.NaT
        price_slice["finance_events_today"] = [[] for _ in range(len(price_slice))]
        price_slice["finance_gap_flag"] = True
        return price_slice

    # Aggregate daily finance events into lists for alignment.
    finance_daily = (
        finance_df.groupby("report_date")
        .apply(lambda group: group.to_dict(orient="records"))
        .rename("finance_events")
        .reset_index()
    )
    finance_daily = finance_daily.sort_values("report_date").reset_index(drop=True)
    finance_daily["finance_summary"] = finance_daily["finance_events"].apply(summarise_finance_events)

    merged = pd.merge_asof(
        price_slice,
        finance_daily[["report_date", "finance_summary"]],
        left_on="date",
        right_on="report_date",
        direction="backward",
    )
    merged = merged.rename(
        columns={
            "finance_summary": "latest_finance_summary",
            "report_date": "latest_finance_report_date",
        }
    )

    # Annotate same-day events for richer context.
    events_today_map = {
        row.report_date: row.finance_events for row in finance_daily.itertuples()
    }
    merged["finance_events_today"] = merged["date"].map(lambda d: events_today_map.get(d, []))
    merged["finance_gap_flag"] = merged["latest_finance_summary"].isna()
    return merged


def main() -> None:
    markets = load_markets()
    price_wide = load_price_history(markets)

    merged_rows: List[pd.DataFrame] = []

    for market_id, group in price_wide.groupby("market_id"):
        finance_df = load_finance_events(market_id)
        merged = merge_market(group.copy(), finance_df)

        meta = markets[market_id]
        merged["event_title"] = meta["event_title"]
        merged["market_question"] = meta["market_question"]
        merged["winning_outcome"] = meta.get("winning_outcome")
        merged_rows.append(merged)

    final_df = pd.concat(merged_rows, ignore_index=True)

    # Serialise finance events list as JSON strings for CSV output.
    final_df["finance_events_today_json"] = final_df["finance_events_today"].apply(json.dumps)

    ordered_columns = [
        "market_id",
        "event_title",
        "market_question",
        "winning_outcome",
        "date",
        *[col for col in final_df.columns if col.startswith("price_")],
        "latest_finance_report_date",
        "latest_finance_summary",
        "finance_gap_flag",
        "finance_events_today_json",
    ]

    # Ensure we only keep unique columns once.
    ordered_columns = [col for col in ordered_columns if col in final_df.columns]
    csv_ready = final_df[ordered_columns].copy()
    csv_ready.to_csv(OUTPUT_CSV, index=False)

    # Prepare JSON payload with finance events preserved as lists.
    json_records = final_df.drop(columns=["finance_events_today_json"]).to_dict(orient="records")
    with OUTPUT_JSON.open("w", encoding="utf-8") as handle:
        json.dump(json_records, handle, default=str, indent=2)

    print(f"Merged market finance dataset saved to {OUTPUT_CSV}")


if __name__ == "__main__":
    main()
